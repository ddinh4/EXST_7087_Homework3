{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011b2618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (3673, 11) (3673,)\n",
      "Testing dataset shape: (1225, 11) (1225,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv('winequality-white.csv', sep=';')\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.values[:,:-1],\n",
    "    df.values[:,-1:],\n",
    "    test_size=0.25,\n",
    "    random_state=42)\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "print('Training dataset shape:', X_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', X_test.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d599bbc2",
   "metadata": {},
   "source": [
    "**Is the testing dataset, the sampling data set you use because the original dataset in too large?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b299eb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    8.7s finished\n",
      "\n",
      "[2023-02-19 23:15:45] Features: 1/5 -- score: 0.49631837476134866[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    7.1s finished\n",
      "\n",
      "[2023-02-19 23:15:52] Features: 2/5 -- score: 0.5434287938608685[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    6.6s finished\n",
      "\n",
      "[2023-02-19 23:15:59] Features: 3/5 -- score: 0.602773360025209[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    6.7s finished\n",
      "\n",
      "[2023-02-19 23:16:06] Features: 4/5 -- score: 0.6199169586090567[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    5.8s finished\n",
      "\n",
      "[2023-02-19 23:16:12] Features: 5/5 -- score: 0.6335346345622718"
     ]
    }
   ],
   "source": [
    "# Build RF classifier to use in feature selection\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "# Build step forward feature selection\n",
    "sfs1 = sfs(clf,\n",
    "           k_features=5,\n",
    "           forward=True,\n",
    "           floating=False,\n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=5)\n",
    "\n",
    "# Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5f8d5e",
   "metadata": {},
   "source": [
    "The best performing model, given the scoring metric, is some subset of 5 features, with a score of 0.638 (uses cross validation so will be different than that which is reported on our full models below, using train and test sets)\n",
    "\n",
    "**This means that given the requirement of it being only 5 features, the accuracy will only be around 0.6?\n",
    "**To clarify, the features in this scenario is talking about the 5/12 attributes wine quality is measured by, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cae867e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5, 7, 10]\n"
     ]
    }
   ],
   "source": [
    "# Which features?\n",
    "feat_cols = list(sfs1.k_feature_idx_)\n",
    "print(feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "049258e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on selected features: 0.562\n",
      "Testing accuracy on selected features: 0.519\n"
     ]
    }
   ],
   "source": [
    "# Build full model with selected features\n",
    "# Builds a classifier on only the subset of selected features\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=4)\n",
    "clf.fit(X_train[:, feat_cols], y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train[:, feat_cols])\n",
    "print('Training accuracy on selected features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test[:, feat_cols])\n",
    "print('Testing accuracy on selected features: %.3f' % acc(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58a7a7",
   "metadata": {},
   "source": [
    "If we were concerned with the end result, and wanted to know if our feature selection troubles had been worth it:\n",
    "-Compare the resultant accuracies of the full model built using the selected features (immediately above) with the resultant accuracies of another full model using all of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fa6e974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy on all features: 0.566\n",
      "Testing accuracy on all features: 0.509\n"
     ]
    }
   ],
   "source": [
    "# Build full model on ALL features, for comparison\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42, max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "print('Training accuracy on all features: %.3f' % acc(y_train, y_train_pred))\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "print('Testing accuracy on all features: %.3f' % acc(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea5309d",
   "metadata": {},
   "source": [
    "We can see that both the selected features model and all features are similar accuracy and perform poorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad87fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
